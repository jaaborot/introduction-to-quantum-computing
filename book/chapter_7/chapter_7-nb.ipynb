{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COARE and ASTI’s Quantum Circuit Simulation Project \n",
    "*by Cyrel Jon Fontelo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents} Table of Contents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "High-Performance Computing (HPC) is a large computer composed of a collection of many smaller, separate servers (computers) known as nodes. These nodes are connected to each other with a fast interconnect to facilitate rapid data transfer. With this infrastructure, HPC is able to solve complex and high-speed computation problems that cannot be performed by an average computer.\n",
    "\n",
    "Supercomputer development was originally driven to be used in applications related to national security, including nuclear weapons design and cryptography. Later on, this technology was employed by the aerospace, automotive industries, scientific research, quantum mechanics, weather forecasting, engineering, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The First Supercomputer\n",
    "\n",
    "**CDC 6600 by [Seymour Cray](https://en.wikipedia.org/wiki/Seymour_Cray), 1964**\n",
    "\n",
    "In the year 1964, the Control Data Corporation (CDC) 6600 made its first appearance as the world's fastest computer. It was designed by Seymour Cray, with a peak performance of up to three million floating-point (FLOPS) or 3 Mega-FLOPS (MFLOPS), and the term ***supercomputer*** was coined to describe it.\n",
    "\n",
    "```{figure} src/640px-CDC_6600.jc.jpg\n",
    ":align: center\n",
    "\n",
    "*Image source: [https://commons.wikimedia.org/wiki/File:CDC_6600.jc.jpg](https://commons.wikimedia.org/wiki/File:CDC_6600.jc.jpg)*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cray-1 Seymour Cray, 1976**\n",
    "\n",
    "Seymour Cray, the architect of the CDC 6600, started his own company, Cray Research Inc., in 1972. The company's first product, released in 1976, was the **Cray-1**. It was also the first supercomputer to successfully implement the vector processor design, also known as an array processor, which is a central processing unit (CPU) that executes a set of instructions in large one-dimensional arrays. With a peak performance of up to 160 million floating-point (FLOPS) or 160 Mega-FLOPS (MFLOPS).\n",
    "\n",
    "```{figure} src/Cray-1-deutsches-museum.jpg\n",
    ":align: center\n",
    "\n",
    "*Image source: [https://commons.wikimedia.org/wiki/File:Cray-1-deutsches-museum.jpg](https://commons.wikimedia.org/wiki/File:Cray-1-deutsches-museum.jpg)*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOST-ASTI COARE\n",
    "\n",
    "The Computing and Archiving Research Environment (COARE) was established in 2014 at the Advanced Science and Technology Institute (ASTI) of DOST. COARE is a High-Performance Computing, Data Archiving, and Science Cloud facility that provides free access to its services for the science community.\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "| ![Image 1](src/coare-1.png) | ![Image 2](src/coare-2.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COARE Services: \n",
    "\n",
    "*DOST ASTI COARE has 3 services available:*\n",
    "\n",
    "\n",
    "1. **High-Performance Computing (HPC)**\n",
    "   <p> The High Performance Computing service is designed to support researchers in their computational tasks, including data analysis and simulations. </p>\n",
    "\n",
    "    - **Compute node capacity**\n",
    "      - *CPU nodes x 36. Each has:*\n",
    "          - 88 logical CPUs, with a total of 3168 Cores(CPU)\n",
    "          - 500 GB RAM, with a total of 18 Terabytes of RAM\n",
    "      - The current capacity is 30 TFLOPS or 30 Trillion Floating point operations per second\n",
    "      ---\n",
    "      - *GPU nodes*\n",
    "        - P40 nodes x 6. Each has:\n",
    "          - 24 CPUs\n",
    "          - 1 TB RAM\n",
    "          - NVIDIA Tesla P40 GPU x 1\n",
    "        - A100 nodes  x 2. Each has:\n",
    "          - 128 CPUs  \n",
    "          - 1 TB RAM\n",
    "          - NVIDIA Tesla A100 GPU x 8\n",
    "      - The current capacity is 75 TFLOPS or 75 Trillion Floating point operations per second\n",
    "      ---\n",
    "    - **Storage capacity**\n",
    "      - 1015 TB of storage capacity\n",
    "      ---      \n",
    "    - **Network capacity**\n",
    "      - 10 gigabits/second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Science Cloud**\n",
    "   \n",
    "    Another service provided by COARE is Science Cloud, which is a Platform as a Service (PaaS). This service is cloud-based and ready-to-use for developing, running, maintaining, and managing applications. It is implemented through OpenStack.\n",
    "  \n",
    "    - Compute and Storage capacity\n",
    "      - 3360 Virtual Cores\n",
    "      - 12.5 TB RAM\n",
    "      - 2790 TB of storage capacity\n",
    "    --- \n",
    "    - Default allocation per user of Science Cloud service.\n",
    "      - 4 logical core (CPU)\n",
    "      - 8 GB RAM (Memory)\n",
    "      - 100 GB (Storage)\n",
    "      - 4 max number of instances (Instance are the virtual server can be created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Data Archiving**\n",
    "\n",
    "   Another service offered by COARE is Data Archiving, which provides a repository that can accommodate various storage requirements, offers multiple storage options, and has a large storage capacity for COARE users. This service is implemented through the Data Catalog, a web-based research repository that is accessible to the public. The datasets stored in this repository could be integral for academics, data analysts, scientists, and other scholars in the scientific community.\n",
    "\n",
    "    - 1 Petabyte (PB) of storage capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who can avail for the services?\n",
    "COARE services are available and can be used by the following:\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|:----:|:----:|:----:|:----:|:----:|\n",
    "| ![Image 1](src/meteorologist.png) | ![Image 2](src/researchers.png) | ![Image 3](src/weather-forecaster.png) | ![Image 4](src/scientists.png) | ![Image 5](src/students.png) |\n",
    "| Meteorologist | Researchers | Weather Forecasters | Scientists | Students |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPC Service and Users\n",
    "\n",
    "``` {figure} src/hpc/hpc_services_n_users.png\n",
    ":align: center\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Life Applications\n",
    "\n",
    "3KRG Rice Genome Project\n",
    "HPC is utilized by various IRRI groups for the analysis of the 3,000 Rice Genomes Project and other newly sequenced genomes\n",
    "\n",
    "```{figure} src/hpc/irri.png\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Philippine Rice Information System (PRiSM)\n",
    "The first rice monitoring system in Southeast Asia that uses digital technologies, such as remote sensing, GIS, and web platform\n",
    "PhilRice uses COARE HPC to process large rice-related datasets, automate the\n",
    "download of satellite images, and process and generate maps\n",
    "\n",
    "```{figure} src/hpc/prism.png\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Weather Research and Forecasting Project\n",
    "PAGASA utilized the HPC service to provide a high-resolution (5km) climate change projection using the WRF model\n",
    "Aims to contribute to strengthening communities' and ecosystems' resilience\n",
    "and adaptive capacity to climate-related hazards and natural disasters by providing timely and accurate disaster and climate information that will support risk-informed planning, particularly at the local level.\n",
    "\n",
    "```{figure} src/hpc/pagasa.png\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic commands for Linux\n",
    "\n",
    "Linux commands are essential tools consisting of text-based instructions used for its operating system to perform various tasks and interact with the computer or server. Each command has a specific purpose and syntax, and they are typically written in ***lowercase***.\n",
    "\n",
    "```{figure} src/basic_commands.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **`pwd`:** Print current directory\n",
    "2. **`cd`:** It stands for “change directory”.\n",
    "    - `cd .` makes you stay at the same directory you are at.\n",
    "    - `cd ..`` makes you shift one directory back. For example, you are at “/home/task/files” and you type “cd..” and hit enter. This will move you to “home/task”.\n",
    "    - `cd -` makes you go to the previous location you were at. For example, you were at “/home” but you moved to “/dir”. Typing “cd-” command will take you back to “/home”.\n",
    "    - `cd ~` will take you to your home directory and “cd /” will take you to root directory.\n",
    "3. **`mkdir`:** Create a new directory <br> \n",
    "    `Syntax: mkdir <directory-name>`\n",
    "4. **`ls`:** Stands for list command which is used to display all the contents in a folder or directory.\n",
    "    - `ls -a` will show you all the files in a directory”.\n",
    "    - `ls -h` will show the files while showing their sizes as well.\n",
    "    - `ls -r` will recursively show the subdirectories of the directory\n",
    "    - `ls -alh` will show you more details about the files contained in a folder. The details include the user permissions, last updated date, date of creation, time and the permission allotted to it like read, write and update.\n",
    "5. **`cp`:** Stands for copy command that basically copies a file in Linux. <br> \n",
    "    `Syntax: cp <file-source> <destination-of-the-file>`\n",
    "    - `cp -r`` copies all the contents of a folder.\n",
    "    - `cp -f` will force the copy process by deleting the destination file if a file with the same name happens to be there at the destination.\n",
    "    - `cp -i` will give you a warning message before actually proceeding with the copying process.\n",
    "    - `cp -u` will update the file in the destination folder only if the files have different content.\n",
    "    - `cp -n` will first check if the file already exists and if it does, it just won’t copy. It doesn’t overwrite the file.\n",
    "    - `cp -a` will archive the file.\n",
    "6. **`mv`:** Moves the file from one place to another. <br>\n",
    "    `Syntax: mv <file-source> <destination-of-the-file>`\n",
    "7. **`touch`:** Create a new file with any kind of extension like text, php and html or without extension. <br>\n",
    "    `Syntax: touch <filename.extension>`\n",
    "8. **`rm`:** Delete a file from the server. <br>\n",
    "    `Syntax: rm <filename>`\n",
    "    - `rm *` will delete all the files or content in a directory.\n",
    "    - `rmdir` will remove the complete directory or folder.\n",
    "    - `rm -r filename or foldername` will delete the folder as well as the folders inside it.\n",
    "9. **`cat`:** Display content of a file on the screen. <br>\n",
    "    `Syntax: cat <filename>`\n",
    "    - The cat command is also used to concatenate two files and show their content combined as one.\n",
    "        `Syntax: cat [file1.txt] [file2.txt] > mergedfile.txt`\n",
    "        “***>***” is the output redirection character\n",
    "    - The cat command can also be used to create a new file.\n",
    "        `Syntax: cat > filename.extension`\n",
    "10. **`head`:** Read the first ten lines of the content inside a file. <br>\n",
    "    `Syntax: head filename.extension`\n",
    "    - You can also give the names of more than one file in the head command and it will show the first ten lines of each file separately.\n",
    "        `Syntax: head /dir1/file1 /dir2/file2`\n",
    "    - You can also change the number of lines you want to be displayed on the screen rather than the default first ten lines.\n",
    "        `Syntax: head -n15 filename.extension`\n",
    "        This will display the first fifteen lines of content from the given file.\n",
    "11. **`tail`:** Read the last ten lines of content from the file. <br>\n",
    "    `Syntax: tail filename.extension`\n",
    "    - Also, you can provide multiple file names to the tail command for it to show last ten lines from each of the mentioned file.\n",
    "        `Syntax: tail /dir1/file1 /dir2/file2`\n",
    "    - Similar to the head command, the tail command also allows you to change the number of lines you want to be displayed other than the default number.\n",
    "        `Syntax: tail -n15  filename.extension`\n",
    "        This will display the last fifteen lines of content from the given file.\n",
    "12. **`tar`:** It stands for tape archive. Also used to compress and decompress folders. <br>\n",
    "    - For compressing, that creates an archive\n",
    "        `Syntax: tar -cvf <output-folder.tar> <folder-to-compress>` <br>\n",
    "        example: `tar -cvf folder1.tar demofolder`\n",
    "    - For decompressing\n",
    "        `Syntax: tar -xvf folder1.tar`\n",
    "13. **`chmod`:** Stands for `change mode`. This command can change permissions of a file or directory. These permissions can be represented either by numbers from 0 to 7 or with alphanumeric characters. 4 represents reading permission, 2 represents writing permission, 1 represents executing permission and 0 represents no permission. <br>\n",
    "    `Syntax: chmod 754 filename`\n",
    "    - In the above command, 7,5,4 represents the permission for the user, group and others wherein 7 is the combination of 4,2 and 1, which indicates all the three permissions are given to the user.\n",
    "    - Similarly, 5 is the combination of 4, 0 and 1, which indicates read, no write and execute permission.\n",
    "    - Also, 4 is the combination of 4, 0 and 0, which indicates read, no write and no execute permission.\n",
    "    - `chmod -r` lets you change the permission of a folder and all the files inside it as well.\n",
    "14. **`grep`:** Search for a particular string inside a file or folder. It returns the whole line containing the phrase if it finds the perfect match. <br>\n",
    "    `Syntax: grep “string” filename`\n",
    "    - The option i in the command “grep -i “string” filename” lets you search for a string case-insensitively in the file.\n",
    "    - To count the number of appearances of a string in the given file, use the command `grep -c “string” filename`.\n",
    "    - To display the filename that contains a particular pattern or string using the command `grep -l “string” *`.\n",
    "    - To display the line number along with the result using the command “grep -n `string” filename`.\n",
    "15. **`find`:** This command searches for a file inside a folder.\n",
    "    - If you want to find a file in some directory, use the command `find /directory -name filename.extension`.\n",
    "    - You can look for any type of file, say a php file by using the command `find . type f -name filename.php`.\n",
    "\n",
    "16. **`vi`:** Vi is a classic and lightweight text editor available on most Unix-based systems. In command mode, you can navigate, search, and perform various operations on the text. <br>\n",
    "    `Syntax: vi filename.txt`\n",
    "    1. Navigate within the file in command mode:\n",
    "        - Use arrow keys or \"h\" (left), \"j\" (down), \"k\" (up), \"l\" (right) for movement.\n",
    "        - To search for a word, press \"/\" and type the word, then press \"Enter.\"\n",
    "        - To delete a character, press \"x.\"\n",
    "    2. Enter insert mode to make changes:\n",
    "        - Press \"i\" to insert text before the cursor.\n",
    "        - Press \"a\" to insert text after the cursor.\n",
    "    3. Save and exit:\n",
    "        - Press \"Esc\" to return to command mode.\n",
    "        - Type `:w` to save changes.\n",
    "        - Type `:wq` to save and exit.\n",
    "17. **`vim`:** Vim is an extended and feature-rich version of Vi with improved functionality. <br>\n",
    "    `Syntax: vim filename.txt`\n",
    "    1. Navigate within the file in command mode:\n",
    "        - Use arrow keys or \"h,\" \"j,\" \"k,\" and \"l\" for movement.\n",
    "        - To search for a word, press \"/\" and type the word, then press \"Enter.\"\n",
    "        - To delete a character, press \"x.\"\n",
    "    2. Enter insert mode to make changes:\n",
    "        - Press \"i\" to insert text before the cursor.\n",
    "        - Press \"a\" to insert text after the cursor.\n",
    "    3. Save and exit:\n",
    "        - Press \"Esc\" to return to command mode.\n",
    "        - Type `:w` to save changes.\n",
    "        - Type `:wq` to save and exit.\n",
    "18. **`nano`:** Nano is a lightweight and straightforward text editor available on many Unix systems. It provides an easy-to-use, menu-driven interface with on-screen help. Unlike Vi/Vim, Nano does not have different modes. It allows you to start editing right away. <br>\n",
    "    `Syntax: nano filename.txt`\n",
    "    - Common keyboard shortcuts:\n",
    "        - To save the file, press Ctrl + O, then press Enter.\n",
    "        - To exit Nano, press Ctrl + X.\n",
    "        - To cut (delete) text, press Ctrl + K.\n",
    "        - To paste text, press Ctrl + U.\n",
    "        - To search for text, press Ctrl + W.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to a High-Performance Computing (HPC)\n",
    "\n",
    "To connect to an HPC, you will need to use an SSH client. Some popular SSH client software includes:\n",
    "\n",
    "- **PuTTY (Windows):** PuTTY is a free and open-source SSH and telnet client for Windows. It is a popular choice for connecting to remote Linux servers. PuTTY is also known for its support for a wide range of authentication methods, including passwords, public key authentication, and Kerberos.\n",
    "- **mRemoteNG (Windows):** mRemoteNG is a free and open-source remote connection manager for Windows. It supports a variety of remote connection protocols, including SSH, RDP, VNC, and Telnet.\n",
    "- **OpenSSH (Linux and macOS):** OpenSSH is a free and open-source suite of cryptographic tools that includes an SSH client and server. It is the default SSH client and server on Linux and macOS systems. OpenSSH is a powerful and versatile SSH tool, and it is used by millions of people around the world.\n",
    "- **Termius (macOS):** Termius is a commercial SSH and telnet client for macOS. It is known for its user-friendly interface.\n",
    "\n",
    "Once you have installed an SSH client, you will need to know the hostname or IP address of the HPC, as well as your username and password. This information should be provided to you by the HPC administrator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to an HPC from Windows 10, Linux or MacOS using terminal and other CLI software:\n",
    "\n",
    "1. Open a terminal window.\n",
    "\n",
    "2. Type the following command, replace ***hostname*** with the hostname or IP address of the HPC:\n",
    "\n",
    "      *`ssh your_username@<hostname or ip address>`* \n",
    "\n",
    "3. If you are asked for a password, enter your password.\n",
    "      ```{note}\n",
    "      *You can also use SSH keys instead of passwords by generating them on your local machine and copying them over to the remote server.*\n",
    "      ```\n",
    "\n",
    "4. After successfully logging in, you will now be connected to the HPC and can execute commands as if you were on the HPC itself.\n",
    "\n",
    "5. When you're done, type `exit` to close the connection, and you'll be redirected back to your local machine.\n",
    "      ```{note}\n",
    "      *Some may encounter an error while using the passwordless access (SSH keys) to access the HPC. These are some common errors:*\n",
    "      - ***Permission denied (publickey) :*** This error indicates that you haven't added the public key on the remote server yet.\n",
    "      - ***Permission denied (publickey) :*** To resolve this issue, you need to add the public key to the authorized_keys file on the remote server.\n",
    "      - ***Bad Permissions (Unprotected private key file!) :*** This error occurs when the permissions on your private key file are too open or allow access to others. To resolve this issue, it's best practice to change the permission type of your private key file to 600 (read and write for the user only).\n",
    "      ```\n",
    "\n",
    "```{tip}\n",
    "|   |\n",
    "|:----:|\n",
    "| ![Linux-MacOS](src/linux-terminal.png \"Terminal Linux and MacOS\") |\n",
    "| *Image of a wsl (Windows subsystem for linux)* |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to an HPC from Windows using PuTTY:\n",
    "\n",
    "1. Open PuTTY.\n",
    "\n",
    "2. In the \"*Host Name (or IP address)*\" field, enter the hostname or IP address of the HPC.\n",
    "\n",
    "3. In the \"*Port*\" field, enter 22 (the default SSH port).\n",
    "\n",
    "4. Click the \"*Open*\" button.\n",
    "\n",
    "5. When prompted, enter your username and password.\n",
    "   \n",
    "6. Once you have connected to the HPC, you will be able to access your files and run jobs.\n",
    "\n",
    "```{figure} src/putty.png\n",
    ":alt: putty\n",
    ":scale: 85%\n",
    ":align: center\n",
    "*Putty (Windows)*\n",
    "```\n",
    "\n",
    "```{figure} src/putty-terminal.png\n",
    ":alt: putty-terminal\n",
    ":scale: 65%\n",
    ":align: center\n",
    "*An example of being prompted for username and password*\n",
    "```\n",
    "\n",
    "```{note}\n",
    "*Private key can also be use while using the PuTTY.*\n",
    "- *Expand `Connection tab/category`*\n",
    "- *Expand `SSH tab/category`*\n",
    "- *Click the `Auth` and find `Private key file for authentication:`*\n",
    "- *Browse your Private key file*\n",
    "```\n",
    "\n",
    "```{figure} src/putty-with-private-key.png\n",
    ":alt: putty-private-key\n",
    ":scale: 100%\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SSH Key Pairs\n",
    "\n",
    "The SSH key pair consists of a private key and a public key. The public key should be provided to COARE, while the private key should be securely stored on your personal device (*which can be your personal computer or in the cloud*). The private key will be used every time a user logs in to the HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate using Linux / MacOS / WSL\n",
    "\n",
    "1. Open a terminal window.\n",
    "2. Type the following command:\n",
    "    ***`ssh-keygen [<args>]`***\n",
    "3. When prompted, enter a filename for the private key. The default filename is `id_rsa`.\n",
    "4. You will also be prompted to enter a passphrase for your private key. This passphrase is used to encrypt your private key, so it is important to choose a strong one.\n",
    "5. Re-enter the passphrase to confirm it.\n",
    "6. Once the private key has been generated, ssh-keygen will generate the corresponding public key and save it to a file with the `.pub` extension. The default filename is `id_rsa.pub`.\n",
    "7. By default, the location of the key pair will be on the `/home-directory/user/.ssh/` folder.\n",
    "\n",
    "    Here is an example of how to generate a private/public key pair using ssh-keygen:\n",
    "```{figure} src/ssh-keygen-1.png\n",
    ":alt: ssh-keygen\n",
    ":scale: 75%\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate using PuTTY key Generator (Windows)\n",
    "\n",
    "1. Open PuTTYgen.\n",
    "   ```{figure} src/puttygen/puttygen.png\n",
    "   :scale: 85%\n",
    "   :align: center\n",
    "   ```\n",
    "2. Select the type of key to generate.\n",
    "3. Enter the number of bits in the key. 2048 bits is a good key size for most purposes.\n",
    "   ```{figure} src/puttygen/puttygen2.png\n",
    "   :scale: 85%\n",
    "   :align: center\n",
    "   ```\n",
    "4. Click Generate.\n",
    "5. Move the mouse around the blank area of the Key section to generate random characters. The green progress bar will advance as you move the mouse.\n",
    "   ```{figure} src/puttygen/puttygen3.png\n",
    "   :scale: 85%\n",
    "   :align: center\n",
    "   ```\n",
    "6. (Optional) Enter a passphrase in the Key passphrase and Confirm passphrase fields. A passphrase adds an extra layer of security to your key pair.\n",
    "   ```{figure} src/puttygen/puttygen4.png\n",
    "   :scale: 85%\n",
    "   :align: center\n",
    "   ```\n",
    "7. Click Save private key.\n",
    "8. Save the private key file to a secure location.\n",
    "9. Click Save public key.\n",
    "10. Save the public key file to a secure location.\n",
    "    ```{figure} src/puttygen/puttygen5.png\n",
    "    :scale: 85%\n",
    "    :align: center\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Keep in mind that this private key is your personal belonging. <br>\n",
    "**DO NOT** send to anyone else your private key.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing DOST-ASTI COARE HPC   \n",
    "\n",
    "The DOST-ASTI COARE HPC is accessible only through ***passwordless SSH***, which requires appending SSH key(s) to the user's account. To apply for an account, please click this [link](https://asti.dost.gov.ph/coare/wiki/Main/using-coare/applying-for-access/first-time-access/). <br>\n",
    "\n",
    "Once you have applied for the account and your public key has been appended, you can log in to the HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logging In using Linux / MacOS / WSL\n",
    "\n",
    "To login to the HPC, use this command in your preferred terminal: <br>\n",
    "***`ssh -i <path-to-your-ssh-private-key> <username>@saliksik.asti.dost.gov.ph -v`*** \n",
    "```{note}\n",
    "*Log in using **IP Address**, use the command.* <br>\n",
    "***`ssh -i <path-to-your-ssh-private-key> <username>@202.90.149.55 -v`***\n",
    "```\n",
    "\n",
    "- `-i` option specifies the path to your private key file, for default this is located to `~/.ssh/id_rsa`. <br>\n",
    "- `-v` option will print more messages about its operation. This can be helpful for error messages and other relevant details. Adding more `v` will increase its verbosity (*i.e*., `-vv` and `-vvv`). <br>\n",
    "\n",
    "After successfully logging in, a welcome page will be displayed.\n",
    "\n",
    "```{figure} src/coare-login.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "*A welcome page after logging in successfully*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging  In using PuTTY (Windows)\n",
    "\n",
    "1. Open PuTTY.\n",
    "2. In the \"*Host Name (or IP address)*\" field, enter the hostname or IP address of the COARE HPC.\n",
    "3. In the \"*Port*\" field, enter 22 (the default SSH port).\n",
    "```{figure} src/putty.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "4. Click the `Auth` and browse your `Private key`\n",
    "5. Click the \"*Open*\" button.\n",
    "```{figure} src/putty-with-private-key.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload and Downloading files\n",
    "\n",
    "Uploading and downloading files from the server refers to the two-way process of sending files from a local device to a remote server (**uploading**) or retrieving files from the server to the local device (**downloading**). This common data transfer method is essential for tasks like sharing documents, accessing cloud storage, and ensuring data backups and synchronization between devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scp ( Linux / MacOS / WSL)\n",
    "\n",
    "Secure Copy Protocol (SCP), is a command-line tool for securely transferring files between a local and a remote host using the SSH (Secure Shell) protocol. It provides a straightforward and secure way to copy files and directories, ensuring data encryption during transmission. SCP is commonly used for tasks like uploading and downloading files to and from remote servers, making it an essential tool for developers, and users who need to move files between local and remote systems with confidence in their data's security. <br>\n",
    "`Syntax: scp [options] source_file_or_directory destination` <br>\n",
    "\n",
    "**[options]**: This part is optional and allows you to specify various options to customize the behavior of SCP. Some common options include:\n",
    "- `-r`: Recursively copy directories and their contents.\n",
    "- `-P <port>`: Specify a non-standard SSH port to connect to the remote host.\n",
    "- `-i <identity_file>`: Use a specific SSH private key file for authentication.\n",
    "- `-v`: Enable verbose mode for more detailed output.\n",
    "- `-q`: Quiet mode, which suppresses non-error messages.\n",
    "\n",
    "Here are some examples of `SCP` usage:\n",
    "1. Copy a local file to a remote server: <br>\n",
    "    `scp local_file.txt user@remote_server:/path/to/remote/directory/`\n",
    "2. Copy a remote file to a local directory: <br>\n",
    "    `scp user@remote_server:/path/to/remote_file.txt /local/directory/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WinSCP ( Windows )\n",
    "\n",
    "WinSCP (Windows Secure Copy) is a popular and user-friendly graphical file transfer tool for Windows. It combines the functionality of SCP (Secure Copy Protocol) with an easy-to-use interface, allowing users to securely transfer files between a local Windows computer and a remote server over SSH (Secure Shell) or SFTP (SSH File Transfer Protocol). WinSCP offers features like drag-and-drop file transfers, remote file management, and text editor integration, making it a convenient choice for Windows users who need to interact with remote servers. <br> \n",
    "Download and install [WinSCP](https://winscp.net/eng/download.php) on your Windows computer and launch the application.\n",
    "\n",
    "\n",
    "To log in to the HPC, enter the following parameters in its interface:\n",
    "\n",
    "1. File protocol: SFTP\n",
    "2. Host name: saliksik.asti.dost.gov.ph (or 202.90.149.55)\n",
    "3. Port number: 22\n",
    "4. User name: (your HPC username)\n",
    "5. Password: (leave as blank)\n",
    "\n",
    "```{figure} src/winscp.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "6. Click `Advanced...` button, this will bring up the Advanced Site Settings window.\n",
    "7. Navigate `Authentication` tab\n",
    "8. Under the `Private key file:` browse the private key that was created using PuTTYgen.\n",
    "9. Click Ok.\n",
    "\n",
    "```{figure} src/winscp-2.png\n",
    ":scale: \n",
    ":align: center\n",
    "```\n",
    "\n",
    "10. Click the `Login` button to connect to the HPC. Upon successful log in, WinSCP will bring up new interface where local and remote files are shown. Left portion will be for local and right portion for remote files.\n",
    "\n",
    "```{figure} src/winscp-3.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules and Environments\n",
    "\n",
    "Modules simplify access to necessary tools, enabling users to switch between configurations and software versions without conflicts, ensuring an efficient computing environment. In HPC servers, environments are custom configurations for scientific tasks, combining software modules, system settings, and resources tailored to specific projects. Users select and activate these setups for efficient and dependency-ready computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Commands \n",
    "\n",
    "1. View available modules: <br>\n",
    "    `Syntax: module avail`\n",
    "```{figure} src/module-avail.png\n",
    ":scale: 85%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "2. Load a module: <br>\n",
    "    `Syntax: module load <module_name/version>`\n",
    "3. Check loaded modules: <br>\n",
    "    `Syntax: module list`\n",
    "4. Unload a module: <br>\n",
    "    `Syntax: module unload <module_name>`\n",
    "5. Unload all loaded modules <br>\n",
    "    `Syntax: module purge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaconda ( Environment )\n",
    "\n",
    "Anaconda is a package and environment manager written primarily in Python and create isolated environments for different projects.\n",
    "\n",
    "1. Initialize the conda <br>\n",
    "    `Syntax: module load anaconda/3-2023.07-2`\n",
    "2. Create a new anaconda environment <br>\n",
    "    `Syntax: conda create --name myenv python` or `conda create --name myenv python=3.8`\n",
    "3. Activate the environment <br>\n",
    "    `Syntax: conda activate myenv`\n",
    "4. Install packages. For example, to install the numpy package:\n",
    "    `Syntax: conda install numpy`\n",
    "5. Deactivate the environment <br>\n",
    "    `Syntax: conda deactivate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLURM\n",
    "\n",
    "SLURM (Simple Linux Utility for Resource Management) is the native scheduler software for COARE's HPC cluster. It efficiently allocates and manages computing resources, including CPUs, memory, and GPUs, among multiple users and tasks. Users can submit, monitor, and optimize jobs, ensuring efficient resource utilization in high-performance computing environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions and Quality-of-Service (QOS)\n",
    "The compute nodes are grouped into partitions and each partition has its default QOS.\n",
    "\n",
    "| **Partition** | **Nodes** | **QOS** | **Limits** | **Remarks** |\n",
    "|:---|:---|:---|---:|---:|\n",
    "| debug | saliksik-cpu-[21-22] | debug_default | 86 CPUs, 1 day run time |\n",
    "| batch | saliksik-cpu-[01-20,25-36] | batch_default | 86 CPUs, 7 days run time |\n",
    "| serial | saliksik-cpu-[23-24] | serial_default | 86 CPUs, 14 days run time |\n",
    "| gpu | saliksik-gpu-[01-06] | gpu-p40_default | 12 CPUs, 1 GPU, 3 days run time | To use the GPU, use either the <br> `#SBATCH --gres=gpu:p40:1` or <br> `#SBATCH --gres=gpu:1` job parameter |\n",
    "| gpu_a100 | saliksik-gpu-[09-10] | *currently for limited access only* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Parameters\n",
    "\n",
    "1. **Required Parameters:** <br>\n",
    "        These are required prior to run any job.\n",
    "    - `--account:` (string) group account where job quotas are set;\n",
    "    - `--partition:` (string) which partition the job will be submitted to;\n",
    "    - `--qos:` (string) the appropriate QOS in the partition;\n",
    "    - `--nodes:` (integer) number of nodes to request;\n",
    "    - `--ntasks:` (integer) total number of CPUs to request;\n",
    "    - `--output:` (string) job log file \n",
    "\n",
    "2. **Optional Parameters:** <br>\n",
    "    - `--ntasks-per-node:` (integer) specify the number of CPUs per node to be requested (must not contradict --ntasks if also specified);\n",
    "    - `--mem:` (string) memory per node (e.g., 1G, 500K, 4GB, etc.);\n",
    "    - `--job-name:` (string) name for the job; will be displayed in job monitoring commands (as discussed later);\n",
    "    - `--error:` (string) job error file; recommended to not define this parameter and use only --output instead;\n",
    "    - `--requeue:` (no arg) make job eligible for requeue;\n",
    "    - `--mail-type:` (string) send an email to the user when the job is in the specified status, such as NONE, BEGIN, END, FAIL, REQUEUE, ALL, etc. (see sbatch manual for more info);\n",
    "    - `--mail-user:` (string) user's email address;\n",
    "\n",
    "```{seealso}\n",
    "[SLURM (sbatch)](https://slurm.schedmd.com/sbatch.html)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Script\n",
    "\n",
    "A job script outlines a computational task's specifics, including software, resource allocation, and input/output files. It's crucial for managing and executing complex workloads in HPC environments. <br>\n",
    "Here is sample job script.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --account=<slurm_group_acct>\n",
    "#SBATCH --partition=<partition>\n",
    "#SBATCH --qos=<qos>\n",
    "#SBATCH --nodes=<num_nodes>\n",
    "#SBATCH --ntasks=<num_cpus>\n",
    "#SBATCH --job-name=\"<jobname>\"\n",
    "#SBATCH --output=\"%x.out\"         ## <jobname>.<jobid>.out\n",
    "##SBATCH --mail-type=ALL          ## optional\n",
    "##SBATCH --mail-user=<email_add>  ## optional\n",
    "##SBATCH --requeue                ## optional\n",
    "##SBATCH --ntasks-per-node=1      ## optional\n",
    "##SBATCH --mem=24G                ## optional: mem per node\n",
    "##SBATCH --error=\"%x.%j.err\"      ## optional; better to use --output only\n",
    "\n",
    "## For more `sbatch` options, use `man sbatch` in the HPC, or go to https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "## Set stack size to unlimited.\n",
    "ulimit -s unlimited\n",
    "\n",
    "## Benchmarking.\n",
    "start_time=$(date +%s.%N)\n",
    "\n",
    "## Print job parameters.\n",
    "echo \"Submitted on $(date)\"\n",
    "echo \"JOB PARAMETERS\"\n",
    "echo \"SLURM_JOB_ID          : ${SLURM_JOB_ID}\"\n",
    "echo \"SLURM_JOB_NAME        : ${SLURM_JOB_NAME}\"\n",
    "echo \"SLURM_JOB_NUM_NODES   : ${SLURM_JOB_NUM_NODES}\"\n",
    "echo \"SLURM_JOB_NODELIST    : ${SLURM_JOB_NODELIST}\"\n",
    "echo \"SLURM_NTASKS          : ${SLURM_NTASKS}\"\n",
    "echo \"SLURM_NTASKS_PER_NODE : ${SLURM_NTASKS_PER_NODE}\"\n",
    "echo \"SLURM_MEM_PER_NODE    : ${SLURM_MEM_PER_NODE}\"\n",
    "\n",
    "## Create a unique temporary folder in the node. Using a local temporary folder usually results in faster read/write for temporary files.\n",
    "custom_tmpdir=\"yes\"\n",
    "\n",
    "if [[ $custom_tmpdir == \"yes\" ]]; then\n",
    "   JOB_TMPDIR=/tmp/${USER}/SLURM_JOB_ID/${SLURM_JOB_ID}\n",
    "   mkdir -p ${JOB_TMPDIR}\n",
    "   export TMPDIR=${JOB_TMPDIR}\n",
    "   echo \"TMPDIR                : $TMPDIR\"\n",
    "fi\n",
    "\n",
    "## Reset modules.\n",
    "module purge\n",
    "module load <module1> [<module2> ...]\n",
    "\n",
    "## Main job. Run your codes and executables here; `srun` is optional.\n",
    "[srun] /path/to/exe1 <arg1> ...\n",
    "[srun] /path/to/exe2 <arg2> ...\n",
    "\n",
    "## Flush the TMPDIR.\n",
    "if [[ $custom_tmp == \"yes\" ]]; then\n",
    "   rm -rf $TMPDIR\n",
    "   echo \"Cleared the TMPDIR (${TMPDIR})\"\n",
    "fi\n",
    "\n",
    "## Benchmarking\n",
    "end_time=$(date +%s.%N)\n",
    "echo \"Finished on $(date)\"\n",
    "run_time=$(python -c \"print($end_time - $start_time)\")\n",
    "echo \"Total runtime (sec): ${run_time}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Management \n",
    "\n",
    "1. **Submit Job Script** <br>\n",
    "It is recommended to submit the job inside the folder containing the job script. It is also recommended that any and all input and/or output files be within the same folder where the job script is located. This is to avoid changing working directories which may result in confusion and possible errors in accessing files/folders. For example, if the job folder is at `/home/username/scratch3/test-job` where all the necessary input files are stored together with the job script named `job.sbatch`. <br>\n",
    "`Syntax: cd /home/username/scratch3/test-job` This is to ensure that the job will run on the scratch folder\n",
    "`Syntax: sbatch job.sbatch` or `sbatch job.sh`\n",
    "\n",
    "2. **Show Job Queue** <br>\n",
    "`Syntax: squeue -u <username>`\n",
    "\n",
    "3. **Show Job Parameters** <br>\n",
    "`Syntax: scontrol show job <job_id>  # or jobid=<job_id>`\n",
    "\n",
    "4. **Check Node and/or Partition Status** <br>\n",
    "`Syntax: sinfo [-p <partition> | -n <nodelist>]`\n",
    "\n",
    "5. **Cancel Job(s)** <br>\n",
    "`Syntax: scancel <job_id1> [<job_id2> ...]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "|   |   |\n",
    "| :--- | ---: |\n",
    "| An Overview of Cluster Computing | `https://www.geeksforgeeks.org/an-overview-of-cluster-computing/` |\n",
    "| Supercomputer <br> CDC 6600 <br> Cray-1 | `https://www.britannica.com/technology/supercomputer#ref1070668` |\n",
    "| Conversion Calculator | `https://www.convert-measurement-units.com/conversion-calculator.php` |\n",
    "| History of Supercomputers | `https://www.extremetech.com/extreme/125271-the-history-of-supercomputers` |\n",
    "| Supercomputer | `https://en.wikipedia.org/wiki/Supercomputer#` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
